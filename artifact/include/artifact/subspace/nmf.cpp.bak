#include "nmf.h"


using namespace subspace;

nmf::nmf(const dataset & V_):V(V_)
{
}


nmf::~nmf(void)
{
}

//% NMF by alternative non-negative least squares using projected gradients
//% Author: Chih-Jen Lin, National Taiwan University
//
//% problem: 
//% min: 1/2 ||WH-V||^2 + 1/2\lambda*||W||^2
//%  st:  0<= H_ij<=1,  i\in {1,...,d-1}, j \in {1,...,n}
//%           H_dj = 1, j \in {1,...,n}
//
//% W,H: output solution
//% Winit,Hinit: initial solution
//% tol: tolerance for a relative stopping condition
//% timelimit, maxiter: limit of time and iterations
//
//% Reference:
//% 1. Lin C. Projected gradient methods for nonnegative matrix factorization. Neural computation. 2007;19(10):2756-79. Available at: http://www.ncbi.nlm.nih.gov/pubmed/17716011.


tuple<shared_ptr<MatrixType>, shared_ptr<MatrixType>> nmf::factorize(const MatrixType & Winit,const MatrixType & Hinit,double lambda, double tol, int maxiter);
{
	
	shared_ptr<MatrixType> W ( new MatrixType(Winit));
	shared_ptr<MatrixType> H ( new MatrixType(Hinit));

	MatrixType gradW = (*W)*((*H)*(*H).transpose()) - V*(*H).transpose()+ lambda*(*W); 
	MatrixType gradH = ((*W).transpose()*(*W))*(*H) - (*W).transpose()*V; //  eq (2) in 1;
	
	double initgrad = sqrt(gradW.squaredNorm() + gradH.squaredNorm());//norm([gradW; gradH'],'fro');
	//fprintf('Init gradient norm %f\n', initgrad);
	double tolW = max(0.001,tol)*initgrad; 
	double tolH = tolW;

	for (int iter=0; iter< maxiter;iter ++)
	{
		// stopping condition
		NumericType projnorm = norm([gradW(:); gradH(~((gradH>=0 & H<=0.01)|(gradH<=0 & H>=0.99)))]);
		if (projnorm < tol*initgrad )
			break;
		
    int iterW;
		tuple<W,gradW,iterW> = nlssubprob_uncon(V.transpose(),(*H).transpose(),(*W).transpose(),lambda,tolW,1000); 
		W = W.transpose(); gradW = gradW.transpose();
		if iterW==1,
			tolW = 0.1 * tolW;
		end
    
		[H,gradH,iterH] = nlssubprob_con(V,W,H,tolH,1000);
		if iterH==1,
			tolH = 0.1 * tolH;
		end
    
		if rem(iter,10)==0, fprintf('.'); end
	}
	fprintf('\nIter = %d Final proj-grad norm %f\n', iter, projnorm);

}


template<typename P>
tuple<shared_ptr<MatrixType>,MatrixType,int> nlssubprob(const MatrixType & V,const MatrixType & W,const MatrixType & Hinit,const C & constraint, NumericType lambda,NumericType tol,int maxiter)
{
//% H, grad: output solution and gradient
//% iter: #iterations used
//% V, W: constant matrices
//% Hinit: initial solution
//% tol: stopping tolerance
//% maxiter: limit of iterations

H = Hinit; WtV = W'*V; WtW = W'*W;

alpha = 1; beta = 0.1;
for iter=1:maxiter,
    grad = WtW*H - WtV + lambda*H;
    projgrad = norm(grad,'fro'); % norm(grad(grad < 0 | H >0));
    if projgrad < tol,
        break
    end
    
    % search step size
    for inner_iter=1:20,
        %Hn = max(H - alpha*grad, 0); d = Hn-H;
        Hn = H - alpha*grad; d = Hn - H;
        gradd=sum(sum(grad.*d)); dQd = sum(sum((WtW*d).*d));
        suff_decr = 0.99*gradd + 0.5*dQd < 0;  % eq (17) in Ref. 1
        if inner_iter==1,
            decr_alpha = ~suff_decr; Hp = H;
        end
        if decr_alpha,
            if suff_decr,
                H = Hn; break;
            else
                alpha = alpha * beta;
            end
        else
            if ~suff_decr | Hp == Hn,
                H = Hp; break;
            else
                alpha = alpha/beta; Hp = Hn;
            end
        end
    end
end

if iter==maxiter,
    fprintf('Max iter in nlssubprob\n');
end

}

function [H,grad,iter] = nlssubprob_con(V,W,Hinit,tol,maxiter)

% H, grad: output solution and gradient
% iter: #iterations used
% V, W: constant matrices
% Hinit: initial solution
% tol: stopping tolerance
% maxiter: limit of iterations

H = Hinit; WtV = W'*V; WtW = W'*W;

alpha = 1; beta = 0.1;
for iter=1:maxiter,
    grad = WtW*H - WtV;
    %projgrad = norm(grad(grad < 0 | H >0));
    projgrad = norm(grad(~((grad>=0 & H<=0.01)|(grad<=0 & H>=0.99))));
    if projgrad < tol,
        break
    end
    
    % search step size
    for inner_iter=1:20,
        %Hn = max(H - alpha*grad, 0); d = Hn-H;
        Hn = max(H-alpha*grad,0.01); Hn = min(Hn,0.99); Hn(end,:) = 1;
        d = Hn - H;
        gradd=sum(sum(grad.*d)); dQd = sum(sum((WtW*d).*d));
        suff_decr = 0.99*gradd + 0.5*dQd < 0;  % eq (17) in Ref. 1
        if inner_iter==1,
            decr_alpha = ~suff_decr; Hp = H;
        end
        if decr_alpha,
            if suff_decr,
                H = Hn; break;
            else
                alpha = alpha * beta;
            end
        else
            if ~suff_decr | Hp == Hn,
                H = Hp; break;
            else
                alpha = alpha/beta; Hp = Hn;
            end
        end
    end
end

if iter==maxiter,
    fprintf('Max iter in nlssubprob\n');
end

end


}
